{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pratica_integrada.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NohopRV8qaTr"
      },
      "source": [
        "**IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9csOqRgB3aE5"
      },
      "source": [
        "#pip install zipcodes\n",
        "#!pip install -U pandasql\n",
        "from folium.plugins import HeatMap\n",
        "import folium\n",
        "import zipcodes\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import pandasql\n",
        "from datetime import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRN7jz1tCh9C"
      },
      "source": [
        "**SPRINT 1: COLETA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b20qfEv3k6R"
      },
      "source": [
        "# Coleta a tabela raíz do site, filtrando pelas datas desejadas\n",
        "df_base = pd.DataFrame(pd.read_html(\"http://www.nuforc.org/webreports/ndxevent.html\")[0])\n",
        "for i, row in df_base.iterrows():\n",
        "  if(row.Reports=='09/1997'):\n",
        "    fim = i+1\n",
        "  elif(row.Reports=='08/2017'):\n",
        "    inicio = i\n",
        "\n",
        "df_base = df_base[inicio:fim]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvfjdNV8ES4f"
      },
      "source": [
        "# Concatenando as tabelas coletadas\n",
        "df = pd.DataFrame()\n",
        "for i, row in df_base.iterrows():\n",
        "  data = row.Reports.split('/')\n",
        "  df2 = pd.DataFrame(pd.read_html(f\"http://www.nuforc.org/webreports/ndxe{data[1]}{data[0]}.html\")[0])\n",
        "  df = pd.concat([df, df2], ignore_index=True)\n",
        "\n",
        "df.columns = ['data_hora' , 'cidade', 'estado', 'formato', 'duracao', 'resumo', 'data_postagem']\n",
        "df.to_csv('OVNIS.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJJJuxTiCnsa"
      },
      "source": [
        "**SPRINT 2: GRÁFICOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7-OVtlx-L0R"
      },
      "source": [
        "# Lendo a base OVNIS\n",
        "ovnis = pd.read_csv(\"OVNIS.csv\")\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT estado, formato, COUNT(*) AS views FROM ovnis\n",
        "WHERE estado IN('CA','FL','WA','TX') AND formato IN('Light','Circle','Triangle','Fireball')\n",
        "GROUP BY estado, formato\n",
        "\"\"\"\n",
        "resultado = pd.DataFrame(pandasql.sqldf(query, locals()))\n",
        "\n",
        "resultado.pivot(\"estado\", \"formato\", \"views\").plot(kind='bar')\n",
        "resultado.pivot(\"estado\", \"formato\", \"views\").plot(kind='bar', stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZN6kvbRgWKx"
      },
      "source": [
        "**SPRINT 2: MAPAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb1hRdksgUoV"
      },
      "source": [
        "# Gera as coordenadas das cidades dos Estados Unidos e salva em csv\n",
        "csv_columns = ['cidade', 'estado', 'lat', 'long']\n",
        "coords = []\n",
        "\n",
        "for i, row in ovnis.iterrows():\n",
        "  try:\n",
        "    lat = zipcodes.filter_by(city=row.cidade, state=row.estado)[0]['lat']\n",
        "    lng = zipcodes.filter_by(city=row.cidade, state=row.estado)[0]['long']\n",
        "  except IndexError:\n",
        "    continue\n",
        "\n",
        "  coords.append({'cidade': row.cidade, 'estado': row.estado, 'lat': lat, 'long': lng})\n",
        "\n",
        "pd.DataFrame(coords).to_csv('coords.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-StE34gal7zr"
      },
      "source": [
        "# Gera as coordenadas das cidades da Califórnia e salva em csv\n",
        "coords_eua = pd.read_csv('coords.csv')\n",
        "query = \"\"\"\n",
        "SELECT cidade, estado, lat, long FROM coords_eua\n",
        "WHERE estado='CA'\n",
        "\"\"\"\n",
        "res = pandasql.sqldf(query, locals())\n",
        "res = pd.DataFrame(res)\n",
        "res.to_csv('coords_ca.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAP3vleai_3e"
      },
      "source": [
        "# Gera o mapa dos Estados Unidos e da Califórnia com suas respectivas ocorrências (1997-2017)\n",
        "coords_eua = pd.read_csv('coords.csv')\n",
        "coords_ca = pd.read_csv('coords_ca.csv')\n",
        "\n",
        "lat_eua = coords_eua.lat.tolist()\n",
        "lng_eua = coords_eua['long'].tolist()\n",
        "lat_ca = coords_ca.lat.tolist()\n",
        "lng_ca= coords_ca['long'].tolist()\n",
        "\n",
        "mapa_eua = folium.Map(location=[37.8427887, -98.3807258], tiles='cartodbdark_matter', zoom_start=4.25)\n",
        "mapa_ca = folium.Map(location=[37.2454668, -120.7021918], tiles='cartodbdark_matter', zoom_start=6)\n",
        "\n",
        "HeatMap(list(zip(lat_eua, lng_eua)), radius=10, overlay=False).add_to(mapa_eua)\n",
        "HeatMap(list(zip(lat_ca, lng_ca)), radius=10, overlay=False).add_to(mapa_ca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqdUazt5qiJf"
      },
      "source": [
        "# Mostrar os mapas\n",
        "mapa_eua\n",
        "mapa_ca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlKJoCuAUVpZ"
      },
      "source": [
        "**SPRINT 3: LIMPEZA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMY-hjPkUbvl"
      },
      "source": [
        "# Lendo o OVNIS.csv, apagando algumas colunas, e criando variáveis de controle\n",
        "ovnis_df = pd.read_csv('OVNIS.csv')\n",
        "ovnis_df = ovnis_df.drop(columns=['ID', 'duracao', 'resumo', 'data_postagem'])\n",
        "estados = pd.read_excel('states.xlsx')['Abbreviation'].tolist()\n",
        "formatos_relevantes = []\n",
        "qr = \"SELECT formato, COUNT(*) AS views FROM ovnis_df GROUP BY formato\"\n",
        "\n",
        "# Verificando quais são os formatos com mais de 1000 ocorrências\n",
        "r = pd.DataFrame(pandasql.sqldf(qr, locals()))\n",
        "for i, row in r.iterrows():\n",
        "  if row.views>=1000:\n",
        "    formatos_relevantes.append(row.formato)\n",
        "\n",
        "''' \n",
        "Percorrendo o dataframe e apagando os registros que:\n",
        "\n",
        "- Não estão dentre os estados dos Estados Unidos;\n",
        "- Possuem registros Unknown\n",
        "- Não pertencem ao grupo de formatos com mais de 1000 ocorrências\n",
        "'''\n",
        "for i, row in ovnis_df.iterrows():\n",
        "  if row.estado not in estados:\n",
        "    ovnis_df.drop(index=i, inplace=True)\n",
        "  elif row.estado=='Unknown' or row.cidade=='Unknown' or row.formato=='Unknown':\n",
        "    ovnis_df.drop(index=i, inplace=True)\n",
        "  elif row.formato not in formatos_relevantes:\n",
        "    ovnis_df.drop(index=i, inplace=True)\n",
        "\n",
        "# Percorrendo o dataframe e apagando linhas com registros nulos\n",
        "for i, row in ovnis_df.isna().iterrows():\n",
        "  if row.estado==True or row.cidade==True or row.formato==True:\n",
        "    ovnis_df.drop(index=i, inplace=True)\n",
        "\n",
        "# Ajustando e salvando o arquivo\n",
        "ovnis_df = ovnis_df.reset_index()\n",
        "ovnis_df = ovnis_df.drop(columns=['index'])\n",
        "ovnis_df.to_csv('df_OVNI_limpo.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWv9z_qO3SVd"
      },
      "source": [
        "**SPRINT 3: ACRÉSCIMO DE VARIÁVEIS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbTtr_O3RWF"
      },
      "source": [
        "# Lendo o df_OVNI_limpo.csv, criando listas e variáveis de controle\n",
        "df_limpo = pd.read_csv('df_OVNI_limpo.csv')\n",
        "df_limpo = df_limpo.drop(columns=['Unnamed: 0'])\n",
        "dias = []\n",
        "meses = []\n",
        "weekdays = []\n",
        "horas = []\n",
        "datas = []\n",
        "DIAS = ['Segunda-feira', 'Terça-feira', 'Quarta-feira', 'Quinta-Feira', 'Sexta-feira', 'Sábado', 'Domingo']\n",
        "\n",
        "# Percorrendo o dataframe e adicionando dados às listas criadas\n",
        "for i, row in df_limpo.iterrows():\n",
        "  try:\n",
        "    horas.append(row.data_hora.split(' ')[1])\n",
        "  except IndexError:\n",
        "    horas.append(None)\n",
        "\n",
        "  dt = datetime.strptime(row.data_hora.split(' ')[0], '%m/%d/%y')\n",
        "  meses.append(dt.month)\n",
        "  dias.append(dt.day)\n",
        "  weekdays.append(DIAS[dt.weekday()])\n",
        "  datas.append(row.data_hora.split(' ')[0])\n",
        "\n",
        "# Atualizando o dataframe com novas colunas e salvando o arquivo\n",
        "df_limpo = df_limpo.assign(data=datas, hora=horas, dia_semana=weekdays, dia=dias, mes=meses)\n",
        "df_limpo.drop(columns=['data_hora'], inplace=True)\n",
        "df_limpo.to_csv('df_OVNI_preparado.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNO1qs_-y39"
      },
      "source": [
        "**SPRINT 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAPI7LGJ-tnG"
      },
      "source": [
        "'''Início da Sprint 4'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}